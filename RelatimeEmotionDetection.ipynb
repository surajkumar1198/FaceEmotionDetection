{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading https://files.pythonhosted.org/packages/09/e2/39fd2aad9858c764bc260acdf4bb63f8096415ee2b782cc2f7ea47a12c79/scikit_image-0.17.2-cp36-cp36m-win_amd64.whl (11.5MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading https://files.pythonhosted.org/packages/77/d7/d2c8d51ba0da5b6ea0da416f21041a92b07abcb75a13053981b01f1d32b2/tifffile-2020.7.22-py3-none-any.whl (145kB)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from scikit-image) (5.0.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from scikit-image) (1.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from scikit-image) (3.1.1)\n",
      "Collecting networkx>=2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "Requirement already satisfied: numpy>=1.15.1 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from scikit-image) (1.18.1)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/30/9f/60c3b80bcefc7e3cbc76c0925e05159312cae0f3e8bf822cf50ba30b5312/PyWavelets-1.1.1-cp36-cp36m-win_amd64.whl (4.2MB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (42.0.2.post20191203)\n",
      "Installing collected packages: tifffile, networkx, imageio, PyWavelets, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 imageio-2.9.0 networkx-2.4 scikit-image-0.17.2 tifffile-2020.7.22\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import  cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "EMOTION_DICT = {0:\"ANGRY\", 1:\"DISGUST\", 2:\"FEAR\", 3:\"HAPPY\", 6:\"NEUTRAL\", 4:\"SAD\", 5:\"SURPRISE\"}\n",
    "model = tf.keras.models.load_model(\"facemodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(path):\n",
    "    #converting image to gray scale and save it\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(path, gray)\n",
    "    \n",
    "    #detect face in image, crop it then resize it then save it\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_clip = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(path, cv2.resize(face_clip, (350, 350)))\n",
    "    \n",
    "    #read the processed image then make prediction and display the result\n",
    "    img = image.load_img(path, grayscale=True, target_size=(48, 48))\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    \n",
    "    x /= 255\n",
    "    \n",
    "    custom = model.predict(x)\n",
    "    \n",
    "    a=custom[0]\n",
    "    \n",
    "    emotion_label=np.argmax(a)\n",
    "    \n",
    "    return EMOTION_DICT[emotion_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(text, cap):\n",
    "    while(True):\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, \"Last Emotion was \"+str(text), (95,30), font, 1.0, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(img, \"Press SPACE: FOR EMOTION\", (5,470), font, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "        cv2.putText(img, \"Hold Q: To Quit\", (460,470), font, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord(' '):\n",
    "            cv2.imwrite(\"test.jpg\", img)\n",
    "            text = return_prediction(\"test.jpg\")\n",
    "            first_run(text, cap)\n",
    "            break\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def first_run(text, cap):\n",
    "    while(True):\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, \"Last Emotion was \"+str(text), (95,30), font, 1.0, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(img, \"Press SPACE: FOR EMOTION\", (5,470), font, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "        cv2.putText(img, \"Hold Q: To Quit\", (460,470), font, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord(' '):\n",
    "            cv2.imwrite(\"test.jpg\", img)\n",
    "            text = return_prediction(\"test.jpg\")\n",
    "            rerun(text, cap)\n",
    "            break\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suraj\\.conda\\envs\\vision\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "first_run(\"None\", cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
